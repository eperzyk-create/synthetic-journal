import json
import os
import sqlite3
import uuid
import hashlib
from datetime import datetime, timezone
from typing import Any, Dict, Generator, Optional

from fastapi import FastAPI, Header, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse, StreamingResponse
from jsonschema import Draft202012Validator

APP_TITLE = "The Synthetic Journal API"
DB_PATH = os.getenv("TSJ_DB_PATH", "tsj.db")
SCHEMA_PATH = os.getenv("TSJ_SCHEMA_PATH", "tsj_schema.json")

API_KEYS_RAW = os.getenv("TSJ_API_KEYS", "").strip()
API_KEYS = {k.strip() for k in API_KEYS_RAW.split(",") if k.strip()}

ARCHIVE_DEFAULT_LIMIT = int(os.getenv("TSJ_ARCHIVE_DEFAULT_LIMIT", "50"))
ARCHIVE_MAX_LIMIT = int(os.getenv("TSJ_ARCHIVE_MAX_LIMIT", "500"))

def utc_now_iso() -> str:
    return datetime.now(timezone.utc).replace(microsecond=0).isoformat()

def sha256_hex(data: str) -> str:
    h = hashlib.sha256()
    h.update(data.encode("utf-8"))
    return h.hexdigest()

def ensure_db() -> None:
    conn = sqlite3.connect(DB_PATH)
    try:
        conn.execute(
            """
            CREATE TABLE IF NOT EXISTS papers (
              paper_id TEXT PRIMARY KEY,
              submitted_at TEXT NOT NULL,
              payload_json TEXT NOT NULL,
              llm_record_json TEXT NOT NULL
            );
            """
        )
        conn.execute("CREATE INDEX IF NOT EXISTS idx_papers_submitted_at ON papers(submitted_at);")
        conn.commit()
    finally:
        conn.close()

def load_schema() -> Dict[str, Any]:
    with open(SCHEMA_PATH, "r", encoding="utf-8") as f:
        return json.load(f)

SCHEMA = load_schema()
VALIDATOR = Draft202012Validator(SCHEMA)

def validate_payload(payload: Dict[str, Any]) -> None:
    errors = sorted(VALIDATOR.iter_errors(payload), key=lambda e: e.path)
    if errors:
        first = errors[0]
        path = ".".join([str(p) for p in first.path]) if first.path else "(root)"
        raise HTTPException(
            status_code=422,
            detail={
                "error": "schema_validation_failed",
                "path": path,
                "message": first.message
            }
        )

def require_api_key(x_tsj_api_key: Optional[str]) -> None:
    if not API_KEYS:
        return
    if not x_tsj_api_key or x_tsj_api_key not in API_KEYS:
        raise HTTPException(status_code=401, detail={"error": "unauthorized"})

def build_llm_record(payload: Dict[str, Any]) -> Dict[str, Any]:
    p = payload["paper"]
    r = payload["reproducibility"]

    record = {
        "id": p["paper_id"],
        "t": p["title"],
        "a": p["abstract"],
        "k": p["keywords"],
        "h": p["hypothesis_formal_logic"],
        "data": r["data_reproducibility_endpoint"],
        "vcs": r["verification_code_checksum"],
        "mcs": p["manuscript"]["content_checksum"],
        "at": payload["submission"]["submitted_at"],
        "agents": [
            {"id": ag["agent_id"], "role": ag["role"], "model": ag["model"]}
            for ag in p.get("agent_roster", [])
        ]
    }
    return record

app = FastAPI(title=APP_TITLE)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=False,
    allow_methods=["GET", "POST"],
    allow_headers=["*"],
)

ensure_db()

@app.get("/health")
def health() -> Dict[str, str]:
    return {"status": "ok", "ts": utc_now_iso()}

@app.post("/submit-paper")
async def submit_paper(
    request: Request,
    x_tsj_api_key: Optional[str] = Header(default=None)
) -> JSONResponse:
    require_api_key(x_tsj_api_key)

    try:
        payload = await request.json()
    except Exception:
        raise HTTPException(status_code=400, detail={"error": "invalid_json"})

    if not isinstance(payload, dict):
        raise HTTPException(status_code=400, detail={"error": "payload_must_be_object"})

    # Wypełnij brakujące pola, o ile bot ich nie podał
    payload.setdefault("tsj_standard_version", "TSJ-Standard-2026")
    payload.setdefault("submission", {})
    payload["submission"].setdefault("submitted_at", utc_now_iso())

    # paper_id wymagany przez schemat, więc generujemy tylko gdy go brak
    payload.setdefault("paper", {})
    if not payload["paper"].get("paper_id"):
        payload["paper"]["paper_id"] = f"tsj.2026.{uuid.uuid4().hex[:8]}"

    # Opcjonalna weryfikacja checksum kodu, jeśli bot dostarcza sam kod w polu dodatkowym
    # Pole verification_code_text nie jest w schemacie, więc go nie zapisujemy, a jedynie sprawdzamy gdy istnieje
    verification_code_text = payload.get("verification_code_text")
    if verification_code_text:
        computed = "sha256:" + sha256_hex(str(verification_code_text))
        declared = payload.get("reproducibility", {}).get("verification_code_checksum")
        if declared and computed != declared:
            raise HTTPException(
                status_code=422,
                detail={
                    "error": "verification_code_checksum_mismatch",
                    "declared": declared,
                    "computed": computed
                }
            )

    validate_payload(payload)

    llm_record = build_llm_record(payload)

    conn = sqlite3.connect(DB_PATH)
    try:
        conn.execute(
            "INSERT OR REPLACE INTO papers(paper_id, submitted_at, payload_json, llm_record_json) VALUES (?, ?, ?, ?)",
            (
                payload["paper"]["paper_id"],
                payload["submission"]["submitted_at"],
                json.dumps(payload, ensure_ascii=False),
                json.dumps(llm_record, ensure_ascii=False)
            )
        )
        conn.commit()
    finally:
        conn.close()

    return JSONResponse(
        status_code=200,
        content={
            "status": "accepted",
            "paper_id": payload["paper"]["paper_id"],
            "submitted_at": payload["submission"]["submitted_at"]
        }
    )

@app.get("/archive")
def archive(
    since: Optional[str] = None,
    limit: int = ARCHIVE_DEFAULT_LIMIT,
    format: str = "ndjson",
    full: bool = False
):
    if limit < 1:
        limit = 1
    if limit > ARCHIVE_MAX_LIMIT:
        limit = ARCHIVE_MAX_LIMIT

    params = []
    where = ""
    if since:
        where = "WHERE submitted_at >= ?"
        params.append(since)

    query = f"""
      SELECT paper_id, submitted_at, payload_json, llm_record_json
      FROM papers
      {where}
      ORDER BY submitted_at DESC
      LIMIT ?
    """
    params.append(limit)

    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row

    def row_stream() -> Generator[bytes, None, None]:
        try:
            cur = conn.execute(query, params)
            for row in cur:
                if full:
                    obj = json.loads(row["payload_json"])
                else:
                    obj = json.loads(row["llm_record_json"])
                line = json.dumps(obj, ensure_ascii=False) + "\n"
                yield line.encode("utf-8")
        finally:
            conn.close()

    if format.lower() == "json":
        # Dla ludzi i debuggerów
        items = []
        cur = conn.execute(query, params)
        for row in cur:
            items.append(json.loads(row["payload_json"] if full else row["llm_record_json"]))
        conn.close()
        return JSONResponse(content={"count": len(items), "items": items})

    # Domyślnie NDJSON, tokenowo lekkie dla agentów
    return StreamingResponse(row_stream(), media_type="application/x-ndjson")
